{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 - 词向量运算\n",
    "\n",
    "因为词嵌入的训练是非常耗资源的，所以大部分人都是选择加载训练好的词嵌入数据。在本博客中，我们将学习到：\n",
    "1. 如何加载训练好了的词向量\n",
    "2. 使用余弦相似性计算相似度\n",
    "3. 使用词嵌入来解决“男人与女人相比就像国王与__相比”之类的词语类比问题\n",
    "4. 修改词嵌入以减少性别偏见等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import w2v_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来就是加载词向量了，这里我们使用50维的向量来表示单词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = w2v_utils.read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们加载了以下数据：\n",
    "- words：单词的集合\n",
    "- word_to_vec_map：字典类型，单词到GloVe向量的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n"
     ]
    }
   ],
   "source": [
    "# python 3.x\n",
    "print(word_to_vec_map['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为独热向量不能很好地表示词与词之间的相似性，所以使用了GlovVel向量，它保存了每个单词更多、更有用的信息，我们现在可以看到如何比较两个词的相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - 余弦相似度\n",
    "\n",
    "![](images/a1.png)\n",
    "![](images/cosine_sim.png)\n",
    "<center>图1-1：两个向量之间的夹角余弦值用来衡量它们的相似程度</center>\n",
    "\n",
    "接下来我们要实现一个计算两个词的相似度的函数`cosine_similarity()`\n",
    "\n",
    "提醒：u的范数是这样定义的：$||u||_2 = \\sqrt{\\sum_{i=1}^n u_i^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    u与v的余弦相似度反映了u与v的相似程度\n",
    "    \n",
    "    参数：\n",
    "        u -- 维度为(n,)的词向量\n",
    "        v -- 维度为(n,)的词向量\n",
    "        \n",
    "    返回：\n",
    "        cosine_similarity -- 由上面公式定义的u和v之间的余弦相似度。\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    \n",
    "    # 计算u与v的内积\n",
    "    dot = np.dot(u, v)\n",
    "    \n",
    "    #计算u的L2范数\n",
    "    norm_u = np.sqrt(np.sum(np.power(u, 2)))\n",
    "    \n",
    "    #计算v的L2范数\n",
    "    norm_v = np.sqrt(np.sum(np.power(v, 2)))\n",
    "    \n",
    "    # 根据公式1计算余弦相似度\n",
    "    cosine_similarity = np.divide(dot, norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893615\n",
      "cosine_similarity(ball, crocodile) =  0.27439246261379424\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174202\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "crocodile = word_to_vec_map[\"crocodile\"]\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然你也可以随意修改其他词汇，然后看看它们只的相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - 词类类比\n",
    "\n",
    "在这里，我们将学习解决“A与B相比就类似于C与____ 相比一样”之类的问题，打个比方，“男人与女人相比就像国王与 女皇 相比”。实际上我们需要找到一个词d,然后$e_a,e_b,e_c,e_d$满足以下关系：$e_b-e_a ≈ e_d-e_c$，当然$e_b-e_a$与$e_d-e_c$是使用余弦相似性来判断的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    解决“A与B相比就类似于C与____相比一样”之类的问题\n",
    "    \n",
    "    参数：\n",
    "        word_a -- 一个字符串类型的词\n",
    "        word_b -- 一个字符串类型的词\n",
    "        word_c -- 一个字符串类型的词\n",
    "        word_to_vec_map -- 字典类型，单词到GloVe向量的映射\n",
    "        \n",
    "    返回：\n",
    "        best_word -- 满足(v_b - v_a) 最接近 (v_best_word - v_c) 的词\n",
    "    \"\"\"\n",
    "    \n",
    "    # 把单词转换为小写\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    \n",
    "    # 获取对应单词的词向量\n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "    \n",
    "    # 获取全部的单词\n",
    "    words = word_to_vec_map.keys()\n",
    "    \n",
    "    # 将max_cosine_sim初始化为一个比较大的负数\n",
    "    max_cosine_sim = -100\n",
    "    best_word = None\n",
    "    \n",
    "    # 遍历整个数据集\n",
    "    for word in words:\n",
    "        # 要避免匹配到输入的数据\n",
    "        if word in [word_a, word_b, word_c]:\n",
    "            continue\n",
    "        # 计算余弦相似度\n",
    "        cosine_sim = cosine_similarity((e_b - e_a), (word_to_vec_map[word] - e_c))\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = word\n",
    "            \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian <====> spain -> spanish\n",
      "india -> delhi <====> japan -> tokyo\n",
      "man -> woman <====> boy -> girl\n",
      "small -> smaller <====> large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} <====> {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以随意地去更改上面的词汇，看看能否拿到自己期望的输出，你也可以试试能不能让程序出一点小错呢？比如：small -> smaller <===> big -> ? ,自己试试呗~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small -> smaller <====> big -> competitors\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('small', 'smaller', 'big')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} <====> {} -> {}'.format( *triad, complete_analogy(*triad,word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在词类类比已经完成了，需要记住的是余弦相似度是比较词向量相似度的一种好方法，尽管使用L2距离（欧式距离）来比较也是可以的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - 去除词向量中的偏见（选学）\n",
    "\n",
    "在这一部分，我们将研究反映在词嵌入中的性别偏差，并试着去去除这一些偏差，除了学习这个内容外，这一节还可以磨炼你对单词向量的直觉，这部分包含有线性代数，不是很难，如果你没有学习过线性代数，那么你可以跳过这一节，你也可以继续深入下去\n",
    "\n",
    "我们首先来看一下包含在词嵌入中的性别偏差，我们首先计算一下$g = e_{woman}-e_{man}$，其中$e_{woman}$是单词\"woman\"对应的词向量，$e_{man}$是单词\"man\"对应的词向量，得到的结果g粗略的包含了性别这一概念，但是如果你计算$g_1=e_{mother}-e_{father}$与$g_2=e_{girl}-e_{boy}$的平均值，可能会更准确一点，但是在这里，$e_{woman}-e_{man}$就已经足够了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n",
      " -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n",
      "  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n",
      "  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n",
      "  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n",
      " -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n",
      " -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n",
      "  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n",
      " -0.04371     0.01258   ]\n"
     ]
    }
   ],
   "source": [
    "g = word_to_vec_map['woman'] - word_to_vec_map['man']\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们不考虑不同单词与g的余弦相似度，考虑相似度的正值与余弦值的负值之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john -0.23163356145973724\n",
      "marie 0.315597935396073\n",
      "sophie 0.31868789859418784\n",
      "ronaldo -0.3124479685032943\n",
      "priya 0.17632041839009402\n",
      "rahul -0.16915471039231722\n",
      "danielle 0.24393299216283892\n",
      "reza -0.07930429672199552\n",
      "katy 0.2831068659572615\n",
      "yasmin 0.23313857767928758\n"
     ]
    }
   ],
   "source": [
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "for w in name_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们所看见的，女性的名字与g的与余弦相似度为正，而男性为负，这也不出乎人的意料，我们来看看其他词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipstick 0.2769191625638266\n",
      "guns -0.1888485567898898\n",
      "science -0.060829065409296994\n",
      "arts 0.008189312385880328\n",
      "literature 0.06472504433459927\n",
      "warrior -0.20920164641125288\n",
      "doctor 0.11895289410935041\n",
      "tree -0.07089399175478091\n",
      "receptionist 0.33077941750593737\n",
      "technology -0.13193732447554296\n",
      "fashion 0.03563894625772699\n",
      "teacher 0.17920923431825664\n",
      "engineer -0.08039280494524072\n",
      "pilot 0.0010764498991916787\n",
      "computer -0.10330358873850498\n",
      "singer 0.1850051813649629\n"
     ]
    }
   ],
   "source": [
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for w in word_list:\n",
    "    print (w, cosine_similarity(word_to_vec_map[w], g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现了吗？比如“computer”就接近于“man”，“literature ”接近于“woman”，但是这些都是不对的一些观念，那么我们该如何减少这些偏差呢？\n",
    "\n",
    "对于一些特殊的词汇而言，比如“男演员（actor）”与“女演员（actress）”或者“祖母（grandmother）”与“祖父（grandfather）”之间应该是具有性别差异的，但是其他的词汇比如“接待员（receptionist）”与“技术（technology ）”是不应该有性别差异的，当我们处理这些词汇的时候应该区别对待"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - 消除与性别无关的词汇的偏差\n",
    "\n",
    "![](images/a2.png)\n",
    "![](images/neutral.png)\n",
    "<center>图1-2：单词\"recptionist\"在消除性别偏差前后的示意图</center>\n",
    "\n",
    "现在我们要实现`neutralize()`函数来消除包含在词汇向量里面的性别偏差，给定一个输入：词嵌入（embedding）e，那么我们可以使用下面的公式计算$e^{debiased}$\n",
    "\n",
    "![](images/a3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(word, g, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    通过将“word”投影到与偏置轴正交的空间上，消除了“word”的偏差。\n",
    "    该函数确保“word”在性别的子空间中的值为0\n",
    "    \n",
    "    参数：\n",
    "        word -- 待消除偏差的字符串\n",
    "        g -- 维度为(50,)，对应于偏置轴（如性别）\n",
    "        word_to_vec_map -- 字典类型，单词到GloVe向量的映射\n",
    "        \n",
    "    返回：\n",
    "        e_debiased -- 消除了偏差的向量。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 根据word选择对应的词向量\n",
    "    e = word_to_vec_map[word]\n",
    "    \n",
    "    # 根据公式2计算e_biascomponent\n",
    "    e_biascomponent = np.divide(np.dot(e, g), np.square(np.linalg.norm(g))) * g\n",
    "    \n",
    "    # 根据公式3计算e_debiased\n",
    "    e_debiased = e - e_biascomponent\n",
    "    \n",
    "    return e_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去偏差前receptionist与g的余弦相似度为：0.33077941750593737\n",
      "去偏差后receptionist与g的余弦相似度为：1.1682064664487028e-17\n"
     ]
    }
   ],
   "source": [
    "e = \"receptionist\"\n",
    "print(\"去偏差前{0}与g的余弦相似度为：{1}\".format(e, cosine_similarity(word_to_vec_map[\"receptionist\"], g)))\n",
    "\n",
    "e_debiased = neutralize(\"receptionist\", g, word_to_vec_map)\n",
    "print(\"去偏差后{0}与g的余弦相似度为：{1}\".format(e, cosine_similarity(e_debiased, g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意：你的第二个结果可能与我不一样，但基本上是接近于0的$(10^{-17})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - 性别词的均衡算法\n",
    "\n",
    "接下来我们来看看在关于有特定性别词组中，如何将它们进行均衡，比如“男演员”与“女演员”中，与“保姆”一词更接近的是“女演员”，我们可以消去“保姆”的性别偏差，但是这并不能保证“保姆”一词与“男演员”与“女演员”之间的距离相等，我们要学的均衡算法将解决这个问题\n",
    "\n",
    "均衡算法背后的关键思想是确保一对特定的单词与49维的$g_⊥$距离相等\n",
    "![](images/equalize10.png)\n",
    "线性代数的推导过程要复杂很多（细节见Bolukbasi et al., 2016），但是关键方程如下：\n",
    "![](images/a4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(pair, bias_axis, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    通过遵循上图中所描述的均衡方法来消除性别偏差。\n",
    "    \n",
    "    参数：\n",
    "        pair -- 要消除性别偏差的词组，比如 (\"actress\", \"actor\") \n",
    "        bias_axis -- 维度为(50,)，对应于偏置轴（如性别）\n",
    "        word_to_vec_map -- 字典类型，单词到GloVe向量的映射\n",
    "    \n",
    "    返回：\n",
    "        e_1 -- 第一个词的词向量\n",
    "        e_2 -- 第二个词的词向量\n",
    "    \"\"\"\n",
    "    # 第1步：获取词向量\n",
    "    w1, w2 = pair\n",
    "    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n",
    "    \n",
    "    # 第2步：计算w1与w2的均值\n",
    "    mu = (e_w1 + e_w2) / 2.0\n",
    "    \n",
    "    # 第3步：计算mu在偏置轴与正交轴上的投影\n",
    "    mu_B = np.divide(np.dot(mu, bias_axis), np.square(np.linalg.norm(bias_axis))) * bias_axis\n",
    "    mu_orth = mu - mu_B\n",
    "    \n",
    "    # 第4步：使用公式7、8计算e_w1B 与 e_w2B\n",
    "    e_w1B = np.divide(np.dot(e_w1, bias_axis), np.square(np.linalg.norm(bias_axis))) * bias_axis\n",
    "    e_w2B = np.divide(np.dot(e_w2, bias_axis), np.square(np.linalg.norm(bias_axis))) * bias_axis\n",
    "    \n",
    "    # 第5步：根据公式9、10调整e_w1B 与 e_w2B的偏置部分\n",
    "    corrected_e_w1B = np.sqrt(np.abs(1-np.square(np.linalg.norm(mu_orth)))) * np.divide(e_w1B-mu_B, np.abs(e_w1 - mu_orth - mu_B))\n",
    "    corrected_e_w2B = np.sqrt(np.abs(1-np.square(np.linalg.norm(mu_orth)))) * np.divide(e_w2B-mu_B, np.abs(e_w2 - mu_orth - mu_B))\n",
    "    \n",
    "    # 第6步： 使e1和e2等于它们修正后的投影之和，从而消除偏差\n",
    "    e1 = corrected_e_w1B + mu_orth\n",
    "    e2 = corrected_e_w2B + mu_orth\n",
    "    \n",
    "    return e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========均衡校正前==========\n",
      "cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.1171109576533683\n",
      "cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.3566661884627037\n",
      "\n",
      "==========均衡校正后==========\n",
      "cosine_similarity(e1, gender) =  -0.7165727525843935\n",
      "cosine_similarity(e2, gender) =  0.7396596474928908\n"
     ]
    }
   ],
   "source": [
    "print(\"==========均衡校正前==========\")\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"man\"], g))\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", cosine_similarity(word_to_vec_map[\"woman\"], g))\n",
    "e1, e2 = equalize((\"man\", \"woman\"), g, word_to_vec_map)\n",
    "print(\"\\n==========均衡校正后==========\")\n",
    "print(\"cosine_similarity(e1, gender) = \", cosine_similarity(e1, g))\n",
    "print(\"cosine_similarity(e2, gender) = \", cosine_similarity(e2, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/a5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Emoji表情生成器\n",
    "\n",
    "在这里，我们要学习使用词向量来构建一个表情生成器\n",
    "\n",
    "你有没有想过让你的文字也有更丰富表达能力呢？比如写下“Congratulations on the promotion! Lets get coffee and talk. Love you!”，那么你的表情生成器就会自动生成“Congratulations on the promotion! ? Lets get coffee and talk. ☕️ Love you! ❤️”\n",
    "\n",
    "另一方面，如果你对这些表情不感冒，而你的朋友给你发了一大堆的带表情的文字，那么你也可以使用表情生成器来怼回去\n",
    "\n",
    "我们要构建一个模型，输入的是文字（比如“Let’s go see the baseball game tonight!”），输出的是表情（⚾️）。在众多的Emoji表情中，比如“❤️”代表的是“心”而不是“爱”，但是如果你使用词向量，那么你会发现即使你的训练集只明确地将几个单词与特定的表情符号相关联，你的模型也了能够将测试集中的单词归纳、总结到同一个表情符号，甚至有些单词没有出现在你的训练集中也可以\n",
    "\n",
    "在这里，我们将开始构建一个使用词向量的基准模型（Emojifier-V1），然后我们会构建一个更复杂的包含了LSTM的模型（Emojifier-V2）\n",
    "\n",
    "请注意：你可能需要运行`pip install emoji`命令来获取emoji包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emo_utils\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "importlib.reload(emo_utils)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - 基准模型：Emojifier - V1\n",
    "\n",
    "### 2.1.1 数据集\n",
    "\n",
    "我们来构建一个简单的分类器，首先是数据集（X，Y）：\n",
    "- X：包含了127个字符串类型的短句\n",
    "- Y：包含了对应短句的标签（0 - 4）\n",
    "![](images/dataset_kiank.png)\n",
    "<center>图2-1：EMOJISET - 5类分类问题，这里给出了几个例子</center>\n",
    "\n",
    "现在我们来加载数据集，训练集：127，测试集：56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = emo_utils.read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = emo_utils.read_csv('data/test.csv')\n",
    "\n",
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以随意更改index的值来看看训练集里面到底有什么东西，使用jupyter notebook的用户需要注意的是，由于字体原因，你打印出来的心有可能是黑色的，但是没有任何问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss you so much ❤️\n"
     ]
    }
   ],
   "source": [
    "index  = 3\n",
    "print(X_train[index], emo_utils.label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 - Emojifier-V1的结构\n",
    "\n",
    "在这里，我们要实现一个叫“Emojifier-V1”的基准模型\n",
    "![](images/emo_model.png)\n",
    "<center>图2-2：基准模型（Emojifier-V1）</center>\n",
    "\n",
    "模型的输入是一段文字（比如“l lov you”），输出的是维度为(1,5)的向量，最后在argmax层找寻最大可能性的输出\n",
    "\n",
    "现在我们将我们的标签Y YY转换成softmax分类器所需要的格式，即从(m,1)转换为独热编码(m,5)，每一行都是经过编码后的样本，其中Y_oh指的是“Y-one-hot”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = emo_utils.convert_to_one_hot(Y_train, C=5)\n",
    "Y_oh_test = emo_utils.convert_to_one_hot(Y_test, C=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，你也可以改变index的值来看看独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3对应的独热编码是[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 0 \n",
    "print(\"{0}对应的独热编码是{1}\".format(Y_train[index], Y_oh_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集准备好了，现在我们就来实现这个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 - 实现Emojifier-V1\n",
    "\n",
    "正如图2-2所示，第一步就是把输入的句子转换为词向量，然后获取均值，我们依然使用50维的词嵌入，现在我们加载词嵌入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = emo_utils.read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们加载了：\n",
    "- word_to_index：字典类型的词汇（400,001个）与索引的映射（有效范围：0-400,000）\n",
    "- index_to_word：字典类型的索引与词汇之间的映射\n",
    "- word_to_vec_map：字典类型的词汇与对应GloVe向量的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单词cucumber对应的索引是：113317\n",
      "索引113317对应的单词是：cucumber\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 113317\n",
    "print(\"单词{0}对应的索引是：{1}\".format(word, word_to_index[word]))\n",
    "print(\"索引{0}对应的单词是：{1}\".format(index, index_to_word[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将实现`sentence_to_avg()`函数，我们可以将之分为以下两个步骤：\n",
    "1. 把每个句子转换为小写，然后分割为列表。我们可以使用X.lower() 与 X.split()\n",
    "2. 对于句子中的每一个单词，转换为GloVe向量，然后对它们取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    将句子转换为单词列表，提取其GloVe向量，然后将其平均。\n",
    "    \n",
    "    参数：\n",
    "        sentence -- 字符串类型，从X中获取的样本。\n",
    "        word_to_vec_map -- 字典类型，单词映射到50维的向量的字典\n",
    "        \n",
    "    返回：\n",
    "        avg -- 对句子的均值编码，维度为(50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 第一步：分割句子，转换为列表。\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    # 初始化均值词向量\n",
    "    avg = np.zeros(50,)\n",
    "    \n",
    "    # 第二步：对词向量取平均。\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = np.divide(avg, len(words))\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在应该实现所有的模型结构了，在使用sentence_to_avg()之后，进行前向传播，计算损失，再进行反向传播，最后再更新参数\n",
    "\n",
    "我们根据图2-2实现model()函数，Y o n YonYon是已经经过独热编码后的Y YY，那么前向传播以及计算损失的公式如下：\n",
    "![](images/a6.png)\n",
    "当然你可能有更高效率的向量化实现方式，但是这里我们只使用for循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate=0.01, num_iterations=400):\n",
    "    \"\"\"\n",
    "    在numpy中训练词向量模型。\n",
    "    \n",
    "    参数：\n",
    "        X -- 输入的字符串类型的数据，维度为(m, 1)。\n",
    "        Y -- 对应的标签，0-7的数组，维度为(m, 1)。\n",
    "        word_to_vec_map -- 字典类型的单词到50维词向量的映射。\n",
    "        learning_rate -- 学习率.\n",
    "        num_iterations -- 迭代次数。\n",
    "        \n",
    "    返回：\n",
    "        pred -- 预测的向量，维度为(m, 1)。\n",
    "        W -- 权重参数，维度为(n_y, n_h)。\n",
    "        b -- 偏置参数，维度为(n_y,)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # 定义训练数量\n",
    "    m = Y.shape[0]\n",
    "    n_y = 5\n",
    "    n_h = 50\n",
    "    \n",
    "    # 使用Xavier初始化参数\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # 将Y转换成独热编码\n",
    "    Y_oh = emo_utils.convert_to_one_hot(Y, C=n_y)\n",
    "    \n",
    "    # 优化循环\n",
    "    for t in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            # 获取第i个训练样本的均值\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "            \n",
    "            # 前向传播\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = emo_utils.softmax(z)\n",
    "            \n",
    "            # 计算第i个训练的损失\n",
    "            cost = -np.sum(Y_oh[i]*np.log(a))\n",
    "            \n",
    "            # 计算梯度\n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "            \n",
    "            # 更新参数\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        if t % 100 == 0:\n",
    "            print(\"第{t}轮，损失为{cost}\".format(t=t,cost=cost))\n",
    "            pred = emo_utils.predict(X, Y, W, b, word_to_vec_map)\n",
    "            \n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is suprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，损失为1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "第100轮，损失为0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "第200轮，损失为0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "第300轮，损失为0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 - 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====训练集====\n",
      "Accuracy: 0.9772727272727273\n",
      "=====测试集====\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"=====训练集====\")\n",
    "pred_train = emo_utils.predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print(\"=====测试集====\")\n",
    "pred_test = emo_utils.predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有5个类别，随机猜测的准确率在20%左右，但是仅仅经过127个样本的训练，就有很好的表现。在训练集中，算法看到了“I love you”的句子，其标签为“❤️”，在训练集中没有“adore”这个词汇，如果我们写“I adore you”会发生什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ❤️\n",
      "i love you ❤️\n",
      "funny lol :smile:\n",
      "lets play with a ball ⚾\n",
      "food is ready 🍴\n",
      "you are not happy ❤️\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"you are not happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = emo_utils.predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "emo_utils.print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为词嵌入的原因，“adore”与“love”很相似，所以它可以正确表达出“❤️”，但是在“you are not happy”中却表达了“❤️”，其原因是我们这个算法使用均值，忽略了排序，所以不善于理解“not happy”这一类词汇\n",
    "\n",
    "我们把矩阵打印出来应该会帮助你理解哪些类让模型学习起来比较困难，横轴为预测，竖轴为实际标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t ❤️ \t ⚾ \t :smile: \t :disappointed: \t 🍴\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" \\t {0} \\t {1} \\t {2} \\t {3} \\t {4}\".format(emo_utils.label_to_emoji(0), emo_utils.label_to_emoji(1), \\\n",
    "                                                 emo_utils.label_to_emoji(2), emo_utils.label_to_emoji(3), \\\n",
    "                                                 emo_utils.label_to_emoji(4)))\n",
    "import pandas as pd\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "emo_utils.plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成了这一部分之后，你需要记住的是：\n",
    "1. 即使你只有128个训练样本，你也可以得到很好地表情符号模型，因为词向量是训练好了的，它会给你一个较好的概括能力\n",
    "2. Emojifier-V1是有缺陷的，比如它不会把“This movie is not good and not enjoyable”划分为不好一类，因为它只是将所有单词的向量做了平均，没有关心过顺序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Emojifier-V2：在Keras中使用LSTM模块\n",
    "\n",
    "现在我们构建一个能够接受输入文字序列的模型，这个模型会考虑到文字的顺序。Emojifier-V2依然会使用已经训练好的词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.core import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1)\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - 模型预览\n",
    "\n",
    "我们将实现下面这一个模型：\n",
    "![](images/emojifier-v2.png)\n",
    "<center>图 2-3: Emojifier-V2：一个两层的LSTM的序列分类器</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 - Keras与mini-batching\n",
    "\n",
    "在这个部分中，我们会使用mini-batches来训练Keras模型，但是大部分深度学习框架需要使用相同的长度的文字，这是因为如果你使用3个单词与4个单词的句子，那么转化为向量之后，计算步骤就有所不同（一个是需要3个LSTM，另一个需要4个LSTM），所以我们不可能对这些句子进行同时训练\n",
    "\n",
    "那么通用的解决方案是使用填充。指定最长句子的长度，然后对其他句子进行填充到相同长度。比如：指定最大的句子的长度为20，我们可以对每个句子使用“0”来填充，直到句子长度为20，因此，句子“I love you”就可以表示为$(e_I,e_{love},e_{you},0,0,...,0)$在这个例子中，任何任何一个超过20个单词的句子将被截取，所以一个比较简单的方式就是找到最长句子，获取它的长度，然后指定它的长度为最长句子的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 - 嵌入层（ The Embedding layer）\n",
    "\n",
    "在keras里面，嵌入矩阵被表示为“layer”，并将正整数（对应单词的索引）映射到固定大小的Dense向量（词嵌入向量），它可以使用训练好的词嵌入来接着训练或者直接初始化。在这里，我们将学习如何在Keras中创建一个Embedding()层，然后使用Glove的50维向量来初始化。因为我们的数据集很小，所以我们不会更新词嵌入，而是会保留词嵌入的值\n",
    "\n",
    "在`Embedding()`层中，输入一个整数矩阵（batch的大小，最大的输入长度），我们可以看看下图：\n",
    "![](images/emb_kiank.png)\n",
    "<center>图 2-4: Embedding 层</center>\n",
    "\n",
    "这个例子展示了两个样本通过embedding层，两个样本都经过了`max_len=5`的填充处理，最终的维度就变成了`(2, max_len, 5)`，这是因为使用了50维的词嵌入。\n",
    "\n",
    "  输入的最大的数（也就是说单词索引）不应该超过词汇表包含词汇的数量，这一层的输出的数组的维度为(batch size, max input length, dimension of word vectors)\n",
    "  \n",
    "  第一步就是把所有的要训练的句子转换成索引列表，然后对这些列表使用0填充，直到列表长度为最长句子的长度\n",
    "  \n",
    "  我们先来实现一个函数，输入的是X（字符串类型的句子的数组），再转化为对应的句子列表，输出的是能够让Embedding()函数接受的列表或矩阵（参见图2-4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    输入的是X（字符串类型的句子的数组），再转化为对应的句子列表，\n",
    "    输出的是能够让Embedding()函数接受的列表或矩阵（参见图4）。\n",
    "    \n",
    "    参数：\n",
    "        X -- 句子数组，维度为(m, 1)\n",
    "        word_to_index -- 字典类型的单词到索引的映射\n",
    "        max_len -- 最大句子的长度，数据集中所有的句子的长度都不会超过它。\n",
    "        \n",
    "    返回：\n",
    "        X_indices -- 对应于X中的单词索引数组，维度为(m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]  # 训练集数量\n",
    "    # 使用0初始化X_indices\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "        # 将第i个居住转化为小写并按单词分开。\n",
    "        sentences_words = X[i].lower().split()\n",
    "        \n",
    "        # 初始化j为0\n",
    "        j = 0\n",
    "        \n",
    "        # 遍历这个单词列表\n",
    "        for w in sentences_words:\n",
    "            # 将X_indices的第(i, j)号元素为对应的单词索引\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们就在Keras中构建Embedding()层，我们使用的是已经训练好了的词向量，在构建之后，使用sentences_to_indices()生成的数据作为输入，Embedding()层将返回每个句子的词嵌入\n",
    "\n",
    "我们现在就实现pretrained_embedding_layer()函数，它可以分为以下几个步骤：\n",
    "1. 使用0来初始化嵌入矩阵\n",
    "2. 使用word_to_vec_map来将词嵌入矩阵填充进嵌入矩阵\n",
    "3. 在Keras中定义嵌入层，当调用Embedding()的时候需要让这一层的参数不能被训练，所以我们可以设置trainable=False\n",
    "4. 将词嵌入的权值设置为词嵌入的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    创建Keras Embedding()层，加载已经训练好了的50维GloVe向量\n",
    "    \n",
    "    参数：\n",
    "        word_to_vec_map -- 字典类型的单词与词嵌入的映射\n",
    "        word_to_index -- 字典类型的单词到词汇表（400,001个单词）的索引的映射。\n",
    "        \n",
    "    返回：\n",
    "        embedding_layer() -- 训练好了的Keras的实体层。\n",
    "    \"\"\"\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    \n",
    "    # 初始化嵌入矩阵\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # 将嵌入矩阵的每行的“index”设置为词汇“index”的词向量表示\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    \n",
    "    # 定义Keras的embbeding层\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    \n",
    "    # 构建embedding层。\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # 将嵌入层的权重设置为嵌入矩阵。\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - 构建Emojifier-V2\n",
    "\n",
    "现在我们开始构建Emojifier-V2模型。embedding层我们已经构建完成了，现在我们将它的输出输入到LSTM中\n",
    "![](images/emojifier-v2.png)\n",
    "<center>图 2-3: Emojifier-V2：一个两层的LSTM的序列分类器</center>\n",
    "\n",
    "现在实现Emojifier_V2()函数，模型的输入是(m, max_len)，定义在了input_shape中，输出是(m, C=5)，你可能需要参考Input(shape = ..., dtype = '...'), LSTM(), Dropout(), Dense(), 与 Activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    实现Emojify-V2模型的计算图\n",
    "    \n",
    "    参数：\n",
    "        input_shape -- 输入的维度，通常是(max_len,)\n",
    "        word_to_vec_map -- 字典类型的单词与词嵌入的映射。\n",
    "        word_to_index -- 字典类型的单词到词汇表（400,001个单词）的索引的映射。\n",
    "    \n",
    "    返回：\n",
    "        model -- Keras模型实体\n",
    "    \"\"\"\n",
    "    # 定义sentence_indices为计算图的输入，维度为(input_shape,)，类型为dtype 'int32' \n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # 创建embedding层\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # 通过嵌入层传播sentence_indices，你会得到嵌入的结果\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # 通过带有128维隐藏状态的LSTM层传播嵌入\n",
    "    # 需要注意的是，返回的输出应该是一批序列。\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # 使用dropout，概率为0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # 通过另一个128维隐藏状态的LSTM层传播X\n",
    "    # 注意，返回的输出应该是单个隐藏状态，而不是一组序列。\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # 使用dropout，概率为0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # 通过softmax激活的Dense层传播X，得到一批5维向量。\n",
    "    X = Dense(5)(X)\n",
    "    # 添加softmax激活\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # 创建模型实体\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 因为数据集中所有句子都小于10个单词，所以我们选择max_len=10。在接下来的代码中，你应该可以看到有“20,223,927”个参数，其中“20,000,050”个参数没有被训练（这是因为它是词向量），剩下的是有“223,877”被训练了的。因为我们的单词表有400,001个单词，所以是400 , 001 ∗ 50 = 20 , 000 , 050 400,001*50=20,000,050400,001∗50=20,000,050个不可训练的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 10, 50)            20000050  \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 10, 128)           91648     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_len = 10\n",
    "model = Emojify_V2((max_len,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与往常一样，在Keras中创建模型以后，我们需要编译并评估这个模型。我们可以使用categorical_crossentropy 损失, adam 优化器与 [‘accuracy’] 指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们开始训练模型，Emojifier-V2模型是以(m, max_len)为输入，(m, number of classes)为输出。我们需要将X_train转化为X_train_indices，Y_train转化为Y_train_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = emo_utils.convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要使用X_train_indices 与 Y_train_oh来拟合模型，我们使用epochs = 50 与 batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 1.6054 - accuracy: 0.2727\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5177 - accuracy: 0.3030\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4887 - accuracy: 0.3636\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4120 - accuracy: 0.4621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3374 - accuracy: 0.4773\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1865 - accuracy: 0.5909\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0705 - accuracy: 0.5682\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9242 - accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8413 - accuracy: 0.7045\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6875 - accuracy: 0.7955\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.7955\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7955\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5033 - accuracy: 0.8106\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8864\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4759 - accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6960 - accuracy: 0.7803\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4244 - accuracy: 0.8409\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4309 - accuracy: 0.8409\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8939\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2718 - accuracy: 0.8939\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2271 - accuracy: 0.9242\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1992 - accuracy: 0.9470\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2688 - accuracy: 0.9242\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2332 - accuracy: 0.9242\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4035 - accuracy: 0.8712\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2313 - accuracy: 0.9242\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2233 - accuracy: 0.9242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1920 - accuracy: 0.9470\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1801 - accuracy: 0.9394\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1599 - accuracy: 0.9545\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9545\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1690 - accuracy: 0.9621\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9924\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.9545\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.9697\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1091 - accuracy: 0.9470\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0841 - accuracy: 0.9697\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9697\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9773\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0440 - accuracy: 0.9924\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0631 - accuracy: 0.9697\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9924\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9924\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0537 - accuracy: 0.9848\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1155 - accuracy: 0.9545\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9697\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2051 - accuracy: 0.9242\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f063a5e490>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的模型应在训练集上接近100%的准确率，每个人得到的结果应该是大同小异的。我们来看看在测试集的表现吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 4ms/step - loss: 0.6157 - accuracy: 0.8214\n",
      "Test accuracy =  0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = emo_utils.convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的结果应该在80%到95%之间，我们来看看哪些被分类错误了吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "正确表情：:smile:   预测结果： he got a very nice raise\t❤️\n",
      "正确表情：:smile:   预测结果： she got me a nice present\t❤️\n",
      "正确表情：:disappointed:   预测结果： work is hard\t:smile:\n",
      "正确表情：:disappointed:   预测结果： This girl is messing with me\t❤️\n",
      "正确表情：🍴   预测结果： any suggestions for dinner\t:smile:\n",
      "正确表情：:smile:   预测结果： you brighten my day\t❤️\n",
      "正确表情：:disappointed:   预测结果： My life is so boring\t❤️\n",
      "正确表情：:disappointed:   预测结果： go away\t⚾\n",
      "正确表情：:disappointed:   预测结果： yesterday we lost again\t⚾\n",
      "正确表情：🍴   预测结果： I did not have breakfast :smile:\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('正确表情：'+ emo_utils.label_to_emoji(Y_test[i]) + '   预测结果： '+ X_test[i] + emo_utils.label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以试试自己写一些话来预测，但是要确保你写的词汇包含在了Glove词嵌入内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "you are so beautiful ❤️\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['you are so beautiful'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  emo_utils.label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在以前的Emojiy-V1模型中它不会正确标记“不开心”，但是我们在Emojiy-V2中纠正了它。目前的Emojiy-V2模型在理解否定词上依旧是不大稳定的，这是因为训练集比较小，如果训练集比较大的话LSTM就会表现的更好"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "参考资料：https://blog.csdn.net/u013733326/article/details/97619187\n",
    "\n",
    "在这个项目中，你将构建一个神经机器翻译（NMT）模型，将人类可读日期 (“25th of June, 2009”) 翻译为机器可读日期 (“2009-06-25”). 您将使用注意模型执行此操作, 序列模型中最复杂的序列之一\n",
    "\n",
    "这个notebook 是与NVIDIA的深度学习研究所共同制作的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 将人类可读日期翻译成机器可读日期\n",
    "\n",
    "您将在此处构建的模型可用于从一种语言翻译到另一种语言, 例如从英语翻译成印地语。 但是，语言翻译需要大量数据集，并且通常需要使用 GPU 训练数天。 为了让您在不使用大量数据集的情况下尝试使用这些模型，我们将使用更简单的“日期转换”任务。 “date translation” task\n",
    "\n",
    "网络将输入以各种可能格式编写的日期 (例如：“the 29th of August 1958”, “03/30/1968”, “24 JUNE 1987”) 将它们转换为标准化的机器可读日期 (例如：“1958-08-29”, “1968-03-30”, “1987-06-24”). 我们将让网络学会以通用的机器可读格式输出日期YYYY-MM-DD\n",
    "\n",
    "(查看所有格式请查看文件： nmt_utils.py， 计算并弄清楚格式的工作原理, 以后会用到 !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - 数据集\n",
    "\n",
    "我们将在 10000 组人类可读日期，并且与之对应的，标准化的机器可读日期的数据集上训练模型。运行下面的单元价值数据集并且打印一些样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 49147.07it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.11.19', '2019-11-10'),\n",
       " ('9/10/70', '1970-09-10'),\n",
       " ('saturday april 28 1990', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('08 jul 2008', '2008-07-08'),\n",
       " ('8 sep 1999', '1999-09-08'),\n",
       " ('thursday january 1 1981', '1981-01-01')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经加载了：\n",
    "- dataset：一个元组列表 (人类可读日期, 机器可读日期)\n",
    "- human_vocab：一个python字典，将人类可读日期中使用的所有字符映射到整数值索引\n",
    "- machine_vocab：一个python字典，将机器可读日期中使用的所有字符映射到整数值索引。这些索引不一定与 human_vocab 的索引一致\n",
    "- inv_machine_vocab：machine_vocab的逆字典，从索引到字符的映射\n",
    "\n",
    "让我们对数据进行预处理，将原始文本数据映射到索引值\n",
    "\n",
    "我们使用：\n",
    "- Tx=30(我们假设人类可读日期的最大长度; 如果我们得到更长的输入，我们将截断它)\n",
    "- Ty=10(因为 “YYYY-MM-DD” 是 10 个字符长度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X：训练集中人类可读日期的处理版本, 其中每个字符都被它在 human_vocab 中映射该字符的索引替换。每个日期都使用特殊字符（）进一步填充。维度为 X.shape = (m, Tx)\n",
    "- Y：训练集中机器可读日期的处理版本, 其中每个字符都被它在machine_vocab中映射的索引替换。 维度为 Y.shape = (m, Ty)\n",
    "- Xoh：X 的 one-hot 版本, one-hot 中条目 “1” 的索引被映射到在human_vocab中对应字符。维度为 Xoh.shape = (m, Tx, len(human_vocab))\n",
    "- Yoh：Y 的 one-hot 版本, one-hot 中条目 “1” 的索引被映射到由于machine_vocab 中对应字符。维度为 Yoh.shape = (m, Tx, len(machine_vocab))。 这里, len(machine_vocab) = 11 因为有 11 字符 (’-’ 以及 0-9)\n",
    "\n",
    "让我们看一下预处理训练样本的一些示例。随意使用index来导航数据集，了解源/目标日期的预处理方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 带注意力的神经机器翻译\n",
    "\n",
    "如果你不得不将一本书的段落从法语翻译成英语, 你不会阅读整段，然后合上书并翻译。甚至在翻译过程中, 您将阅读/重新阅读并专注于与您所写的英语部分相对应的法文段落部分\n",
    "\n",
    "注意机制告诉神经机器翻译模型，它应该在任何一步都要有注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - 注意机制\n",
    "\n",
    "在这部分, 你将实现课程中介绍的注意力机制。这是一个图，以提醒您模型的工作原理。 左侧的图表展示注意力模型。右侧的图表展示了一个“注意”步骤：计算注意力变量$α^{<t,t'>}$，使用注意力变量计算输出中每个时间步$（t=1,...,T_y）$的上下文变量$context^{<T>}$\n",
    "![](images/attn_model.png)\n",
    "![](images/attn_mechanism.png)\n",
    "<center>图1：带注意力的神经机器翻译</center>\n",
    "\n",
    "以下是你可能要注意模型的一些属性：\n",
    "![](images/a1.png)\n",
    "![](images/a2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将共享层定义为全局变量 \n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # 在这个 notebook 我们正在使用自定义的 softmax(axis = 1)\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在您可以使用这些图层来实现 one_step_attention()。为了通过这些层之一传播Keras张量对象X，使用 layer(X) (或 layer([X,Y]) 如果它需要多个输入), 例如， densor（X）将通过上面定义的Dense（1）层传播 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    执行一步 attention: 输出一个上下文向量，输出作为注意力权重的点积计算的上下文向量\n",
    "    \"alphas\"  Bi-LSTM的 隐藏状态 \"a\"\n",
    "    \n",
    "    参数：\n",
    "    a --  Bi-LSTM的输出隐藏状态 numpy-array 维度 (m, Tx, 2*n_a)\n",
    "    s_prev -- (post-attention) LSTM的前一个隐藏状态, numpy-array 维度(m, n_s)\n",
    "    \n",
    "    返回：\n",
    "    context -- 上下文向量, 下一个(post-attetion) LSTM 单元的输入\n",
    "    \"\"\"\n",
    "    \n",
    "    # 使用 repeator 重复 s_prev 维度 (m, Tx, n_s) 这样你就可以将它与所有隐藏状态\"a\" 连接起来。 (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # 使用 concatenator 在最后一个轴上连接 a 和 s_prev (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # 使用 densor1 传入参数 concat, 通过一个小的全连接神经网络来计算“中间能量”变量 e。(≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # 使用 densor2 传入参数 e , 通过一个小的全连接神经网络来计算“能量”变量 energies。(≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # 使用 activator 传入参数 \"energies\" 计算注意力权重 \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # 使用 dotor 传入参数 \"alphas\" 和 \"a\" 计算下一个（(post-attention) LSTM 单元的上下文向量 (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在编写 model() 函数之后，您将能够检查 one_step_attention() 的预期输出\n",
    "\n",
    "练习: 实现 model() 如图1.1和上文所述。 同样，我们已经定义了全局图层用于在 model（） 中共享权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/a3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    Tx -- 输入序列的长度\n",
    "    Ty -- 输出序列的长度\n",
    "    n_a -- Bi-LSTM的隐藏状态大小\n",
    "    n_s -- post-attention LSTM的隐藏状态大小\n",
    "    human_vocab_size -- python字典 \"human_vocab\" 的大小\n",
    "    machine_vocab_size -- python字典 \"machine_vocab\" 的大小\n",
    "\n",
    "    返回：\n",
    "    model -- Keras 模型实例\n",
    "    \"\"\"\n",
    "    \n",
    "    # 定义模型的输入，维度 (Tx,)\n",
    "    # 定义 s0 和 c0, 初始化解码器 LSTM 的隐藏状态，维度 (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # 初始化一个空的输出列表\n",
    "    outputs = []\n",
    "    \n",
    "    \n",
    "    # 第一步：定义 pre-attention Bi-LSTM。 记得使用 return_sequences=True. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True), input_shape=(m, Tx, n_a * 2))(X)\n",
    "    \n",
    "    # 第二步：迭代 Ty 步\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # 第二步.A: 执行一步注意机制，得到在 t 步的上下文向量 (≈ 1 line)\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # 第二步.B: 使用 post-attention LSTM 单元得到新的 \"context\" \n",
    "        # 别忘了使用： initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # 第二步.C: 使用全连接层处理post-attention LSTM 的隐藏状态输出 (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # 第二步.D: 追加 \"out\" 到 \"outputs\" 列表 (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # 第三步：创建模型实例，获取三个输入并返回输出列表。 (≈ 1 line)\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下单元创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 37)]     0           []                               \n",
      "                                                                                                  \n",
      " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 30, 64)       17920       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 30, 64)       0           ['s0[0][0]',                     \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]']                   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30, 128)      0           ['bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[0][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[1][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[2][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[3][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[4][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[5][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[6][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[7][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[8][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[9][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30, 10)       1290        ['concatenate[0][0]',            \n",
      "                                                                  'concatenate[1][0]',            \n",
      "                                                                  'concatenate[2][0]',            \n",
      "                                                                  'concatenate[3][0]',            \n",
      "                                                                  'concatenate[4][0]',            \n",
      "                                                                  'concatenate[5][0]',            \n",
      "                                                                  'concatenate[6][0]',            \n",
      "                                                                  'concatenate[7][0]',            \n",
      "                                                                  'concatenate[8][0]',            \n",
      "                                                                  'concatenate[9][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30, 1)        11          ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]',                  \n",
      "                                                                  'dense[2][0]',                  \n",
      "                                                                  'dense[3][0]',                  \n",
      "                                                                  'dense[4][0]',                  \n",
      "                                                                  'dense[5][0]',                  \n",
      "                                                                  'dense[6][0]',                  \n",
      "                                                                  'dense[7][0]',                  \n",
      "                                                                  'dense[8][0]',                  \n",
      "                                                                  'dense[9][0]']                  \n",
      "                                                                                                  \n",
      " attention_weights (Activation)  (None, 30, 1)       0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_1[1][0]',                \n",
      "                                                                  'dense_1[2][0]',                \n",
      "                                                                  'dense_1[3][0]',                \n",
      "                                                                  'dense_1[4][0]',                \n",
      "                                                                  'dense_1[5][0]',                \n",
      "                                                                  'dense_1[6][0]',                \n",
      "                                                                  'dense_1[7][0]',                \n",
      "                                                                  'dense_1[8][0]',                \n",
      "                                                                  'dense_1[9][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 64)        0           ['attention_weights[0][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[1][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[2][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[3][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[4][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[5][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[6][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[7][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[8][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[9][0]',      \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64),         33024       ['dot[0][0]',                    \n",
      "                                 (None, 64),                      's0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'dot[1][0]',                    \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[0][2]',                   \n",
      "                                                                  'dot[2][0]',                    \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[1][2]',                   \n",
      "                                                                  'dot[3][0]',                    \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[2][2]',                   \n",
      "                                                                  'dot[4][0]',                    \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[3][2]',                   \n",
      "                                                                  'dot[5][0]',                    \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[4][2]',                   \n",
      "                                                                  'dot[6][0]',                    \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[5][2]',                   \n",
      "                                                                  'dot[7][0]',                    \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[6][2]',                   \n",
      "                                                                  'dot[8][0]',                    \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[7][2]',                   \n",
      "                                                                  'dot[9][0]',                    \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[8][2]']                   \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 11)           715         ['lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[9][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "像往常一样，在Keras创建模型后，你需要编译它并定义模型使用的损失, 优化和评估指标。编译模型时，\n",
    "- 损失使用：categorical_crossentropy\n",
    "- 优化算法：learning rate = 0.005,$\\beta_1=0.9,\\beta_2=0.999,decay=0.01$\n",
    "- 评估指标：accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20919\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈2 lines)\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一步定义所有的输入和输出并训练模型：\n",
    "- 你已经有包含训练样例的 X， 维度$(m = 10000,T_x = 30)$\n",
    "- 你需要创建用0初始化的 s0 和 c0，用于初始的 post_activation_LSTM_cell\n",
    "- 给定的 model() ，你需要“输出”11个维度为（m，T_y）元素的列表，以便 outputs[i][0], ..., outputs[i][Ty] 表示第$i^{th}$个训练样本 (X[i])对应的真实标签（字符）。大多数情况下，第$i^{th}$个训练样本中第$j^{th}$个字符的真正的标签是 outputs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们训练模型，迭代一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 5s 46ms/step - loss: 1.7994 - dense_2_loss: 0.0177 - dense_2_1_loss: 0.0119 - dense_2_2_loss: 0.1214 - dense_2_3_loss: 0.2257 - dense_2_4_loss: 0.0594 - dense_2_5_loss: 0.1112 - dense_2_6_loss: 0.3379 - dense_2_7_loss: 0.0850 - dense_2_8_loss: 0.5571 - dense_2_9_loss: 0.2722 - dense_2_accuracy: 0.9939 - dense_2_1_accuracy: 0.9963 - dense_2_2_accuracy: 0.9670 - dense_2_3_accuracy: 0.9562 - dense_2_4_accuracy: 0.9889 - dense_2_5_accuracy: 0.9728 - dense_2_6_accuracy: 0.9304 - dense_2_7_accuracy: 0.9868 - dense_2_8_accuracy: 0.8843 - dense_2_9_accuracy: 0.9447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d90e01df0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练时，您可以看到输出的10个位置中的每个位置的损失和准确性 下表给出了一个例子，说明如果批次有两个例子，精度可能是多少\n",
    "![](images/table.png)\n",
    "\n",
    "所以, dense_2_acc_8: 0.89 表示您在当前批量数据中，89％的时间正确预测输出了第7个字符。\n",
    "  我们已经运行这个模型的时间更长时间，并且保存了权重。运行下面的单元加载我们的权重。（通过几分钟模型训练，您应该能够获得类似精度的模型，但加载我们的模型将节省您的时间。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以在新示例中看到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "source: 5 April 09\n",
      "output: 2000-05-05\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = np.expand_dims(source, axis=0).repeat(m,axis=0)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction[:,0]]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您还可以更改这些示例以使用您自己的示例进行测试。 下一部分将让您更好地了解注意机制在做什么 – 即，在生成特定输出字符时网络注意哪些部分输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 可视化注意力（选学）\n",
    "\n",
    "由于问题的固定输出长度为10，也可以使用10个不同的softmax单元执行此任务，以生成输出的10个字符，但注意模型的一个优点是输出的每个部分（比如月份）都知道它只需要依赖于输入的一小部分（输入中给出月份的字符）我们可以看到输出的哪个部分正在查看输入的哪个部分\n",
    "\n",
    "考虑翻译的任务 “Saturday 9 May 2018” to “2018-05-09”. 如果我们可视化计算的$α^{<t,t'>}$我们得到下面这个：\n",
    "![](images/date_attention.png)\n",
    "<center>图2：完整的注意图</center>\n",
    "\n",
    "注意输出为什么忽略输入的 “Saturday” 部分。输出时间步长没有注意到输入的那部分，我们还看到 9 已被翻译为 09 并且 May 已被正确翻译为 05，输出时要注意翻译所需的输入部分。年份主要要求它注意输入的“18”以生成“2018”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - 从网络获取激活\n",
    "\n",
    "现在让我们可视化您网络中的注意力值。我们将通过传入一个样例给网络，然后可视化$α^{<t,t'>}$的值\n",
    "\n",
    "为了确定注意力值的位置，让我们首先打印模型的摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 37)]     0           []                               \n",
      "                                                                                                  \n",
      " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 30, 64)       17920       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 30, 64)       0           ['s0[0][0]',                     \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]']                   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30, 128)      0           ['bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[0][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[1][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[2][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[3][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[4][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[5][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[6][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[7][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[8][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'repeat_vector[9][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30, 10)       1290        ['concatenate[0][0]',            \n",
      "                                                                  'concatenate[1][0]',            \n",
      "                                                                  'concatenate[2][0]',            \n",
      "                                                                  'concatenate[3][0]',            \n",
      "                                                                  'concatenate[4][0]',            \n",
      "                                                                  'concatenate[5][0]',            \n",
      "                                                                  'concatenate[6][0]',            \n",
      "                                                                  'concatenate[7][0]',            \n",
      "                                                                  'concatenate[8][0]',            \n",
      "                                                                  'concatenate[9][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30, 1)        11          ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]',                  \n",
      "                                                                  'dense[2][0]',                  \n",
      "                                                                  'dense[3][0]',                  \n",
      "                                                                  'dense[4][0]',                  \n",
      "                                                                  'dense[5][0]',                  \n",
      "                                                                  'dense[6][0]',                  \n",
      "                                                                  'dense[7][0]',                  \n",
      "                                                                  'dense[8][0]',                  \n",
      "                                                                  'dense[9][0]']                  \n",
      "                                                                                                  \n",
      " attention_weights (Activation)  (None, 30, 1)       0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_1[1][0]',                \n",
      "                                                                  'dense_1[2][0]',                \n",
      "                                                                  'dense_1[3][0]',                \n",
      "                                                                  'dense_1[4][0]',                \n",
      "                                                                  'dense_1[5][0]',                \n",
      "                                                                  'dense_1[6][0]',                \n",
      "                                                                  'dense_1[7][0]',                \n",
      "                                                                  'dense_1[8][0]',                \n",
      "                                                                  'dense_1[9][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 64)        0           ['attention_weights[0][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[1][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[2][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[3][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[4][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[5][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[6][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[7][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[8][0]',      \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'attention_weights[9][0]',      \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64),         33024       ['dot[0][0]',                    \n",
      "                                 (None, 64),                      's0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'dot[1][0]',                    \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[0][2]',                   \n",
      "                                                                  'dot[2][0]',                    \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[1][2]',                   \n",
      "                                                                  'dot[3][0]',                    \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[2][2]',                   \n",
      "                                                                  'dot[4][0]',                    \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[3][2]',                   \n",
      "                                                                  'dot[5][0]',                    \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[4][2]',                   \n",
      "                                                                  'dot[6][0]',                    \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[5][2]',                   \n",
      "                                                                  'dot[7][0]',                    \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[6][2]',                   \n",
      "                                                                  'dot[8][0]',                    \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[7][2]',                   \n",
      "                                                                  'dot[9][0]',                    \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[8][2]']                   \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 11)           715         ['lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[9][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "浏览上面 model.summary()的输出。你可以看到图层名为 attention_weights 的输出 alphas 维度 (m, 30, 1) 在 dot_2 计算每个时间步$t = 0,...,T_y - 1$的上下文向量之前\n",
    "\n",
    "函数 attention_map（） 从模型中提取注意值并绘制它们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在生成的图上，您可以观察预测输出的每个字符的注意权重值。检查此图并检查网络注意的位置对您有意义，在日期翻译应用程序中，您将观察到大多数时间注意力有助于预测年份，并且对预测日期/月份没有太大影响\n",
    "\n",
    "需要记住的是：\n",
    "- 机器翻译模型可用于从一个序列映射到另一个序列。 它们不仅可用于翻译人类语言（如法语 - >英语），还可用于日期格式翻译等任务\n",
    "- 注意机制允许网络在生成输出的特定部分时关注输入的最相关部分\n",
    "- 使用注意机制的网络可以从长度为$T_x$的输入转换位长度位$T_y$的输出，其中$T_x$和$T_y$可以不同\n",
    "- 你可以将注意力权重$α^{<t,t'>}$可视化，查看在生成每个输出时网络正在关注什么\n",
    "\n",
    "您现在可以实现注意模型并使用它来学习从一个序列到另一个序列的复杂映射"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}